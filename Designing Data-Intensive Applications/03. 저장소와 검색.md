특정 작업부하(workload) 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념을 이해할 필요가 있다.
트랜잭션 작업부하에 맞춰 최적화된 저장소 엔진과 분석을 위해 최적화된 엔진 간에 차이가 있다.


## 큰 목차 

1. 관계형 데이터베이스, NoSQL
2. 로그 구조(log-structured) 계열 저장소 엔진
3. B Tree 같은 페이지 지향 (page-oriented) 계열 저장소 엔진

데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 색인이 필요하다.
동일한 데이터를 여러 가지 다양한 방법으로 검색할때 데이터 각 부분에 다야한 색인이 필요하다.

색인 : 기본 데이터 (primary data) 에서 파생된 추가적인 구조다.


색인을 잘 선택했다면 읽기 질의 속도가 향상되지만 모든 색인은 쓰기 속도를 떨어뜨린다.
- 어떤 종류의 색인이라도 대체로 쓰기 속도를 느리게 한다 데이터 쓸때 매번 색인도 갱신해야 하기 때문에
필요이상으로 오버헤드를 발생시키지 않으면서 애플리케이션에 가장 큰 이익을 안겨주는 색인 선택해야 한다.


## 종류

# 해시 색인 
1. 키-값 저장소는 대부분의 프로그래밍 언어에서 볼 수 있는 사전 타입(dictionary type) 과 매우 유사하다. 
2. 보통 해시맵으로 구현 
3. 간단하게 구현해보기 
    - 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵 유지 
    - 바이트 오프셋은 바로찾을 수 있는 위치 
    - 파일에 새로운 키-값 쌍을 추가할 때마다 방금 기록한 데이터의 오프셋을 반영하기 위해 해시맵도 갱신해야 한다. (새로운 키를 삽입할 때와 존재하는 키 갱신할때 모두 적용)
    - 값을 조회하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다. 
    - 위의 방식은 비트캐스트(Bitcast 리악의 기본 저장소 엔진)가 근본적으로 사용하는 방식이다. 
    - 비트캐스트는 해시 맵을 전부 메모리에 유지하며 사용 가능한 램에 모든 키가 저장된다는 조건을 전제로 고성능 읽기, 쓰기를 보장한다. 
    - 값은 한 번의 디스크 탐색으로 디스크에서 적재할 수 있기 때문에 사용 가능한 메모리보다 더 많은 공간을 사용할 수 있다. 
    - 데이터 파일의 일부가 이미 파일 시스템 캐시에 있다면 읽기에 디스크 입출력이 필요하지 않다.
      - 운영체제는 빈 RAM 을 자동으로 파일 캐시로 사용한다.
        리눅스/윈도우/mac OS 같은 운영체제(OS)는 남는 메모리를 파일 시스템 캐시(page cache) 로 자동 활용한다. 
        디스크에서 어떤 파일을 읽으면 OS 는 그 데이터를 RAM 에 캐싱해 두고 다음에 같은 파일 읽을때 디스크에서 다시 읽지 않고, 캐시에 저장된 RAM 에서 바로 읽어 속도가 빠르다. 
        따라서 Bitcast 의 데이터 파일 중 일부는 자연스럽게 캐시되며 Bitcast 가 따로 조작할 필요가 없다. 
    - Bitcast
      - 인메모리 해시맵을 유지하고 값 가져오기 과정은 아래와 같다. 
      - 1) 해시맵에서 해당 key의 오프셋(offset)을 찾음  → O(1)
        2) 데이터 파일에서 해당 오프셋 위치로 이동
        3) 거기에 저장된 value를 읽음
        -> 오프셋 위치의 파일 내용이 이미 파일 시스템 캐시에 있으면 OS 는 실제 디스크(HDD/SSD) 에서 읽지 않고 대신 RAM 에 있는 캐시된 페이지를 바로 반환 -> 실제로 디스크 I/O 가 발생하지 않음
      - 구조 
        - 키(key)는 모두 메모리에 올려두고 해시맵에 저장된 키와 오프셋 정보를 RAM 에서 즉시 조회 가능
        - 값(value)은 디스크에 저장하지만, 자주 읽히는 부분은 OS 캐시 안에 있어 실제로 디스크를 자주 읽지 않음
        - Bitcast 는 디스크 기반 저장소인데도, 읽기 성능이 메모리 기반 DB 에 가까워짐 
        
   - 파일에 계속 추가시 디스크 공간이 부족해질 때 
     - 특정 크기의 세그먼트(segment) 로 로그를 나누는 방식이 좋은 해결책이다.
     - 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기 수행 -> 세그먼트 파일들에 대해 컴팩션(compaction) 수행 가능 
     - 컴팩션 : 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것 의미
     - 컴팩션은 보통 세그먼트를 더 작게 만든다. 
     - 세그먼트가 쓰여진 후에는 절대 변경할 수 없기 때문에 병합할 세그먼트는 새로운 파일로 만든다. 
   - 실제로 구현할때 세부적으로 고려해야 할 사항
     - 파일 형식
       - CSV는 로그에 가장 적합한 형식이 아니다. 바이트 단위의 문자열 길이를 부화화한 다음 원시 문자열을 부호화하는 바이너리 형식을 사용하는 편이 더 빠르고 간단함
     - 레코드 삭제 
       - 키와 관련된 값을 삭제하려면 데이터 파일에 특수한 삭제 레코드를 추가 필요 
     - 고장(Crash) 복구
       - 데이터 베이스 재시작시 인메모리 해시 맵 손실됨 -> 전체 세그먼트 파일을 처음부터 끝까지 읽고 각 키에 대한 최신 값의 오프셋을 확인해서 각 세그먼트 해시 맵을 복원 가능하지만 파일 크기가 크면 복원 시간 오래걸리며 서버 재시작이 어렵다. 
        비트캐스트는 각 세그먼트 해시 맵을 메모리로 조금 더 빠르게 로딩할 수 있게 스냅숏을 디스크에 저장해 복구 속도를 높인다. 
     - 부분적 레코드 
       - 데이터베이스는 로그에 레코드를 추가하는 도중에도 죽을 수 있기 때문에 비트캐스트 파일은 체크섬을 포함하고 있어 로그의 손상된 부분을 탐지해 무시가능
     - 동시성 제어
       - 쓰기를 엄격하게 순차적으로 로그에 추가할 때 일반적인 구현 방법은 하나의 쓰기 스레드만 사용하는 것이다. 데이터 파일 세그먼트는 추가 전용이거나 불변이므로 다중 스레드로 동시에 읽기 가능 
     
    - 해시 테이블 색인의 제한 사항
      - 해시 테이블은 메모리에 저장해야 하므로 키가 너무 많으면 문제가 될 수 있다.


# SS 테이블과 LSM 트리
    - 키값으로 정렬해보기 
    
    
## 정렬된 문자열 테이블(Sorted String Table / SS 테이블)
    
- 각 키는 각 병합된 세그먼트 파일 내에 한 번만 나타나야 한다. 
    - 해시 색인을 가진 로그 세그먼트가 아닌 장점 
        1. 세그먼트 병합은 파일이 사용 가능한 메모리보다 크더라도 간단하고 효율적임 

    - SS 테이블 생성과 유지 
        - 데이터를 키로 정렬한다면? (유입되는 쓰기는 임의 순서로 발생) 
        - 레드 블랙 트리(red-black tree), AVL 트리 이용해서 임의 순서로 키를 삽입하고, 정렬된 순서로 해당 키를 다시 읽을 수 있다. 

    - 실제 저장소 엔진 생성 과정
      1. 쓰기 -> 인메모리 균형 트리(balanced tree) 데이터 구조 (레드 블랙 트리)에 추가 -> 멤테이블(memtable)\
      2. 멤테이블이 수 메가바이트 정도의 임곗값보다 커지면 ss테이블 파일로 디스크에 기록한다. 트리가 이미 키로 정렬된 키-값 쌍을 유지하고 있기 때문에 효율적으로 수행할 수 있다. 
         새로운 ss 테이블 파일은 데이터베이스의 가장 최신 세그먼트가 된다. 
        ss테이블을 디스크에 기록하는 동안 쓰기는 새로운 멤테이블 인스턴스에 기록한다. 
      3. 읽기 요청을 제공하려면 먼저 멤테이블에서 키를 찾아야 한다. 그 다음 디스크 상의 가장 최신 세그먼트에서 찾고, 그 뒤로 오래된 세그먼트에서 찾는다.
      4. 가끔 세그먼트 파일을 합치고 덮어 쓰여지거나 삭제된 값을 버리는 병합, 컴팩션 과정 수정 
      -> 데이터베이스가 고장나면 디스크로 기록되지 않은 멤테이블에 있는 가장 최신 쓰기의 손실 가능성이 있다. 따라서 이전 절과 같이 매번 쓰기를 즉시 추가할 수 있게 분리된 로그를 디스크 상에 유지해야 한다. 
      멤테이블 ss 테이블로 기록하고 나면 해당 로그는 버리는 것이 가능 


## SS 테이블에서 LSM 트리만들기 

- LSM 저장소 엔진 : 정렬된 파일 병합과 컴팩션 원리를 기반으로 하는 저장소 엔진 
- LSM 트리의 기본 개념 : 백그라운드에서 연쇄적으로 SS 테이블을 지속적으로 병합하는 것 

## 성능 최적화
- 블룸 필터 ( Bloom filter ) 
    LSM 트리 알고리즘은 데이터베이스에 존재하지 않는 키를 찾는 경우 느릴 수 있고, 멤테이블을 확인한 다음 키가 존재하지 않는지 모든 세그먼트를 봐야한다.
    이런 접근을 최적화하기 위해 저장소 엔진이 블룸 필터를 추가적으로 사용한다. 
    블룸 필터는 키가 데이터베이스에 존재하지 않음을 알려주므로 존재하지 않는 키를 위한 불필요한 디스크 읽기를 많이 절약 가능 
-  SS 테이블을 압축하고 병합하는 순서와 시기를 결정하는 다양한 전략 존재
  - 크기 계층 컴팩션(size-tiered compaction) : 좀 더 새롭고 작은 ss 테이블을 상대적으로 오래됐고 큰 SS 테이블에 연이어 병합   
  - 레벨 컴팩션(leveled compaction) : 키 범위를 더 작은 SS 테이블로 나누고 오래된 데이터는 개별 레벨로 이동하기 때문에 컴팩션을 점진적으로 진행해 디스크 공간을 덜 사용 

## B 트리 

- 가장 널리 사용되는 색인 구조 (거의 대부분의 관계형 데이터베이스에서 표준 색인 구현으로 사용하며 비관계형 데이터베이스에서도 많이 사용) 
- ss 테이블과 같이 키로 정렬된 키-값 쌍을 유지하기 때문에 키-값 검색과 범위 질의에 효율적 
- 4kb 크기(때로는 더 큰)의 고정 크기 블록이나 페이지로 나누고 한 번에 하나의 페이지에 읽기 또는 쓰기를 한다. 
- 각 페이지는 주소나 위치를 이용해 식별 가능 
- 하나의 페이지가 다른 페이지를 참조할 수 있다. (포인트와 비슷하지만 메모리 대신 디스크에 있다.)
- 한페이지는 B 트리의 루트(Root) 로 지정된다. 
- 색인에서 키를 찾으려면 루트에서 시작하며 여러 키와 하위 페이지의 참조를 포함한다. 
- 최종적으로는 개별 키 (leaf page) 를 포함하는 페이지에 도달
- B 트리에 존재하는 키의 값을 갱신 : 키를 포함하고 있는 리프 페이지를 검색하고, 페이지의 값을 바꾼 다음 페이지를 디스크에 다시 기록 
- 새로운 키를 추가하려면 새로운 키를 포함하는 범위의 페이지를 찾아 해당 페이지에 키와 값을 추가 
*새로운 키를 수용한 페이지에 충분한 여유 공간이 없다면 페이지 하나를 반쯤 채워진 페이지 둘로 나누고 상위 페이지가 새로운 키 범위의 하위부분들을 알 수 있게 갱신 


## B 트리 최적화

1.

    설명 : 페이지 덮어 쓰기, 고장 복구를 위한 WAL 유지 대신 (LMDB 같은) 일부 데이터베이스는 쓰기 시 복사 방식을 사용한다.
    변경된 페이지는 다른 위치에 기록하고 트리에 상위 페이지의 새로운 버전을 만들어 새로운 위치를 가리키게 한다. -> 동시성 제어에 유용


### 전통적인 B 트리 방식 (In-place Update)
페이지 직접 덮어쓰면 C -> D 로 변경 
- 만약 쓰기 중간에 고장나면 데이터 손상 및 복구 불가능하기 때문에 
해결책: WAL (Write-Ahead Log) 
- 변경 사항을 먼저 로그에 기록
- 그 다음 실제 데이터 변경
- 고장 시 로그로 복구
- 문제점 : WAL 유지 비용, 복잡한 복구 로직 

### Copy-on-Write (COW, 쓰기 시 복사) 방식

기존 데이터를 절대 덮어쓰지 않고, 변경된 새 버전을 다른 곳에 기록 
전통적 방식이 WAL 에 기록하고 실제 페이지를 수정하고 WAL 삭제하는 3단계가 필요했는데 COW 방식은 새 위치에 기록하는 1단계로 끝낸다. 
복구 방식은 : 쓰기 중 고장이 나면 새 버전이 불완전하기 때문에 그냥 구버전을 사용하게 됨 
읽기와 쓰기(새버전) 의 간섭이 없고 Lock 이 불필요하며 읽기가 쓰기를 막지 않는다. 


2. 키 축약 (Key Compression) 
설명 : 페이지에 전체 키를 저장하는 게 아니라 키를 축약해 쓰면 공간 절약 가능
- 내부 노드의 키는 범위 구분만 하면 되므로, 전체 키를 저장할 필요는 없다. 
- 실제 완전한 키는 리프 노드에만 있으면 된다. 
- 실제 구현 예시
  - 공통 접두사 제거 
- 장점
  - 공간 절약, 높은 분기 계수, 트리 깊이 감소, 더 적은 디스크 I/O, 더 많은 내부 노드가 캐시에 적재 
- 단점
  - 복잡도 증가 (키 복원 로직 필요), CPU 오버헤드(압축/해제), 리프 노드에는 여전히 전체 키 필요 

*분기 계수 : 한 노드가 가질 수 있는 최대 자식 노드의 개수 

3. 트리에 포인터 추가
- 각 리프 페이지가 양쪽 형제 페이지에 대한 참조를 가지면 상위 페이지로 다시 이동하지 않아도 순서대로 키를 스캔할 수 있다. 

4. 프랙탈 트리(fractal tree) : 같은 B 트리 변형은 디스크 찾기를 줄이기 위해 로그 구조화 개념을 일부 빌렸다. 



# LSM 트리의 장점

- 쓰기 증폭(write amplification) : 데이터베이스에 쓰기 한 번이 데이터베이스 수명 동안 디스크에 여러 번의 쓰기를 야기하는 것 
- 쓰기가 많은 애플리케이션에서 성능 병목 : 데이터베이스가 디스크에 쓰는 속도 (따라서 쓰기 증폭은 바로 성능 비용이다.)


# LSM 트리의 단점

- 로그 구조화 저장소의 단점은 컴팩션 과정이 떄로는 진행 중인 읽기와 쓰기의 성능에 영향을 준다는 점(B 트리의 성능은 로그 구조화 저장소 엔진보다 예측하기 쉽다.)
- 높은 쓰기 처리량 
  - 디스크의 쓰기 대역폭은 유한하고 초기 쓰기와 백그라운드에서 수행되는 컴팩션 스레드가 이 대역폭 공유 
  - 쓰기 처리량이 높음에도 컴팩션 설정을 잘 하지 않으면 컴팩션이 유입 쓰기 속도를 따라갈 수 없음 -> 디스크 상에 병합되지 않은 세그먼트 수는 디스크 공간이 부족할때 까지 증가
  - SS 테이블 기반 저장소 엔진은 컴팩션이 유입 속도를 따라가지 못해도 유입 쓰기의 속도를 조절하지 않으므로 이런 상황을 감지하기 위한 명시적 모니터링이 필요하다.
- B 트리 : 각 키가 딱 한 곳에만 존재, Lock 관리가 간단, ACID 속성 구현이 직관적, 롤백과 복구과 쉬움, 일관성 보장 
  LSM 트리 : 쓰기 성능은 좋지만, 같은 키가 여러 곳에 존재, 트랜잭션 구현이 복잡, 주로 최종 일관성 모델에 적합 


# 다중 칼럼 색인

- 다중 칼럼 색인의 가장 일반적인 유형 : 결합 색인 
결합 색인은 하나의 칼럼에 다른 칼럼을 추가하는 방식으로 하나의 키에 여러 필드를 단순히 결합 (필드가 연결되는 순서는 색인 정의에 명시)
- 다차원 색인은 한 번에 여러 칼럼에 질의하는 좀 더 일반적 방법 -> 지리 공간 데이터에 중요하게 사용 


# 트랜잭션 처리나 분석 

- OLTP (온라인) : 실시간으로 많은 사용자가 동시에 짧고 간단한 트랜잭션을 빠르게 처리하는 시스템 / 일상적인 비즈니스 업무에 사용되는 데이터베이스 처리 방식
- OLAP (온라인 분석 처리 : online analytic processing) : 분석, 통계 중심 
- 처음에는 트랜잭션 처리와 분석 질의를 위해 동일한 데이터베이스 사용하였으나, 개별 데이터베이스로 분석 수행하게 됨 (데이터 웨어하우스 data warehouse)


# 데이터 웨어하우징 

- OLTP 시스템 : 높은 가용성과 낮은 지연 시간의 트랜잭션 처리 기대 
- 데이터 웨어하우스 : 분석가들이 OLTP 작업에 영향을 주지 않고 마음껏 질의할 수 있는 개별 데이터베이스 
- 데이터는 OTLP 데이터베이스에서 추출(extract) 하고 분석 친화적인 스키마로 변환(transform) 하고 깨끗하게 정리한 다음 데이터 웨어하우스에 적재(load) 한다. 
- 데이터 웨어하우스로 데이터를 가져오는 과정을 ETL(Extract-Transform-Load) 라고 한다.
- 다수의 데이터베이스 벤더는 트랜잭션 처리와 분석 작업부하 양쪽 모두 지원하기보다는 둘 중 하나를 지원하는 데 중점을 둔다. 
- 많은 데이터 웨어하우스는 star schema / 차원 모델링(dimensional modeling) 이라고 알려진 상당히 정형화된 방식을 사용한다.
- 날짜와 시간도 보통 차원 테이블을 사용해 표현한다. -> 차원 테이블을 사용하면 날짜에 대한 추가적인 정보를 부호화할 수 있다. 
- start schema 란 테이블 관계가 시각화될 때 사실 테이블이 가운데에 있고 차원 테이블로 둘러싸고 있다는 사실에서 비롯되었다. 
- 눈꽃송이 모양 스키마(snowflake schema) : 차원이 하위차원으로 더 세분화된다.









