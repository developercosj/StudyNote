특정 작업부하(workload) 유형에서 좋은 성능을 내게끔 저장소 엔진을 조정하려면 저장소 엔진이 내부에서 수행되는 작업에 대해 대략적인 개념을 이해할 필요가 있다.
트랜잭션 작업부하에 맞춰 최적화된 저장소 엔진과 분석을 위해 최적화된 엔진 간에 차이가 있다.


## 큰 목차 

1. 관계형 데이터베이스, NoSQL
2. 로그 구조(log-structured) 계열 저장소 엔진
3. B Tree 같은 페이지 지향 (page-oriented) 계열 저장소 엔진

데이터베이스에서 특정 키의 값을 효율적으로 찾기 위해서는 색인이 필요하다.
동일한 데이터를 여러 가지 다양한 방법으로 검색할때 데이터 각 부분에 다야한 색인이 필요하다.

색인 : 기본 데이터 (primary data) 에서 파생된 추가적인 구조다.


색인을 잘 선택했다면 읽기 질의 속도가 향상되지만 모든 색인은 쓰기 속도를 떨어뜨린다.
- 어떤 종류의 색인이라도 대체로 쓰기 속도를 느리게 한다 데이터 쓸때 매번 색인도 갱신해야 하기 때문에
필요이상으로 오버헤드를 발생시키지 않으면서 애플리케이션에 가장 큰 이익을 안겨주는 색인 선택해야 한다.


## 종류

# 해시 색인 
1. 키-값 저장소는 대부분의 프로그래밍 언어에서 볼 수 있는 사전 타입(dictionary type) 과 매우 유사하다. 
2. 보통 해시맵으로 구현 
3. 간단하게 구현해보기 
    - 키를 데이터 파일의 바이트 오프셋에 매핑해 인메모리 해시 맵 유지 
    - 바이트 오프셋은 바로찾을 수 있는 위치 
    - 파일에 새로운 키-값 쌍을 추가할 때마다 방금 기록한 데이터의 오프셋을 반영하기 위해 해시맵도 갱신해야 한다. (새로운 키를 삽입할 때와 존재하는 키 갱신할때 모두 적용)
    - 값을 조회하려면 해시 맵을 사용해 데이터 파일에서 오프셋을 찾아 해당 위치를 구하고 값을 읽는다. 
    - 위의 방식은 비트캐스트(Bitcast 리악의 기본 저장소 엔진)가 근본적으로 사용하는 방식이다. 
    - 비트캐스트는 해시 맵을 전부 메모리에 유지하며 사용 가능한 램에 모든 키가 저장된다는 조건을 전제로 고성능 읽기, 쓰기를 보장한다. 
    - 값은 한 번의 디스크 탐색으로 디스크에서 적재할 수 있기 때문에 사용 가능한 메모리보다 더 많은 공간을 사용할 수 있다. 
    - 데이터 파일의 일부가 이미 파일 시스템 캐시에 있다면 읽기에 디스크 입출력이 필요하지 않다.
      - 운영체제는 빈 RAM 을 자동으로 파일 캐시로 사용한다.
        리눅스/윈도우/mac OS 같은 운영체제(OS)는 남는 메모리를 파일 시스템 캐시(page cache) 로 자동 활용한다. 
        디스크에서 어떤 파일을 읽으면 OS 는 그 데이터를 RAM 에 캐싱해 두고 다음에 같은 파일 읽을때 디스크에서 다시 읽지 않고, 캐시에 저장된 RAM 에서 바로 읽어 속도가 빠르다. 
        따라서 Bitcast 의 데이터 파일 중 일부는 자연스럽게 캐시되며 Bitcast 가 따로 조작할 필요가 없다. 
    - Bitcast
      - 인메모리 해시맵을 유지하고 값 가져오기 과정은 아래와 같다. 
      - 1) 해시맵에서 해당 key의 오프셋(offset)을 찾음  → O(1)
        2) 데이터 파일에서 해당 오프셋 위치로 이동
        3) 거기에 저장된 value를 읽음
        -> 오프셋 위치의 파일 내용이 이미 파일 시스템 캐시에 있으면 OS 는 실제 디스크(HDD/SSD) 에서 읽지 않고 대신 RAM 에 있는 캐시된 페이지를 바로 반환 -> 실제로 디스크 I/O 가 발생하지 않음
      - 구조 
        - 키(key)는 모두 메모리에 올려두고 해시맵에 저장된 키와 오프셋 정보를 RAM 에서 즉시 조회 가능
        - 값(value)은 디스크에 저장하지만, 자주 읽히는 부분은 OS 캐시 안에 있어 실제로 디스크를 자주 읽지 않음
        - Bitcast 는 디스크 기반 저장소인데도, 읽기 성능이 메모리 기반 DB 에 가까워짐 
        
   - 파일에 계속 추가시 디스크 공간이 부족해질 때 
     - 특정 크기의 세그먼트(segment) 로 로그를 나누는 방식이 좋은 해결책이다.
     - 특정 크기에 도달하면 세그먼트 파일을 닫고 새로운 세그먼트 파일에 이후 쓰기 수행 -> 세그먼트 파일들에 대해 컴팩션(compaction) 수행 가능 
     - 컴팩션 : 로그에서 중복된 키를 버리고 각 키의 최신 갱신 값만 유지하는 것 의미
     - 